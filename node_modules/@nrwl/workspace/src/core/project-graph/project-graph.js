"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const fs_1 = require("fs");
const app_root_1 = require("../../utils/app-root");
const fileutils_1 = require("../../utils/fileutils");
const assert_workspace_validity_1 = require("../assert-workspace-validity");
const file_graph_1 = require("../file-graph");
const file_utils_1 = require("../file-utils");
const normalize_nx_json_1 = require("../normalize-nx-json");
const build_dependencies_1 = require("./build-dependencies");
const build_nodes_1 = require("./build-nodes");
const project_graph_builder_1 = require("./project-graph-builder");
/**
 * This version is stored in the project graph cache to determine if it can be reused.
 */
const projectGraphCacheVersion = '1';
function createProjectGraph(workspaceJson = file_utils_1.readWorkspaceJson(), nxJson = file_utils_1.readNxJson(), workspaceFiles = file_utils_1.readWorkspaceFiles(), fileRead = file_utils_1.defaultFileRead, cache = readCache(), shouldCache = true) {
    assert_workspace_validity_1.assertWorkspaceValidity(workspaceJson, nxJson);
    const normalizedNxJson = normalize_nx_json_1.normalizeNxJson(nxJson);
    if (cache && maxMTime(rootWorkspaceFileData(workspaceFiles)) > cache.mtime) {
        cache = false;
    }
    if (!cache || maxMTime(workspaceFiles) > cache.mtime) {
        const fileMap = file_graph_1.createFileMap(workspaceJson, workspaceFiles);
        const incremental = modifiedSinceCache(fileMap, cache);
        const ctx = {
            workspaceJson,
            nxJson: normalizedNxJson,
            fileMap: incremental.fileMap,
        };
        const builder = new project_graph_builder_1.ProjectGraphBuilder(incremental.projectGraph);
        const buildNodesFns = [
            build_nodes_1.buildWorkspaceProjectNodes,
            build_nodes_1.buildNpmPackageNodes,
        ];
        const buildDependenciesFns = [
            build_dependencies_1.buildExplicitTypeScriptDependencies,
            build_dependencies_1.buildImplicitProjectDependencies,
            build_dependencies_1.buildExplicitNpmDependencies,
        ];
        buildNodesFns.forEach((f) => f(ctx, builder.addNode.bind(builder), fileRead));
        buildDependenciesFns.forEach((f) => f(ctx, builder.nodes, builder.addDependency.bind(builder), fileRead));
        const projectGraph = builder.build();
        if (shouldCache) {
            writeCache({
                version: projectGraphCacheVersion,
                projectGraph,
                fileMap,
            });
        }
        return projectGraph;
    }
    else {
        // Cache file was modified _after_ all workspace files.
        // Safe to return the cached graph.
        return cache.data.projectGraph;
    }
}
exports.createProjectGraph = createProjectGraph;
const distPath = `${app_root_1.appRootPath}/dist`;
const nxDepsPath = `${distPath}/nxdeps.json`;
function readCache() {
    try {
        fs_1.mkdirSync(distPath);
    }
    catch (e) {
        /*
         * @jeffbcross: Node JS docs recommend against checking for existence of directory immediately before creating it.
         * Instead, just try to create the directory and handle the error.
         *
         * We ran into race conditions when running scripts concurrently, where multiple scripts were
         * arriving here simultaneously, checking for directory existence, then trying to create the directory simultaneously.
         *
         * In this case, we're creating the directory. If the operation failed, we ensure that the directory
         * exists before continuing (or raise an exception).
         */
        if (!fileutils_1.directoryExists(distPath)) {
            throw new Error(`Failed to create directory: ${distPath}`);
        }
    }
    const data = getValidCache(fileutils_1.fileExists(nxDepsPath) ? fileutils_1.readJsonFile(nxDepsPath) : null);
    return data ? { data, mtime: file_utils_1.mtime(nxDepsPath) } : false;
}
function getValidCache(cache) {
    if (!cache) {
        return null;
    }
    if (cache.projectGraph &&
        cache.fileMap &&
        cache.version &&
        cache.version === projectGraphCacheVersion) {
        return cache;
    }
    else {
        return null;
    }
}
function writeCache(cache) {
    fileutils_1.writeJsonFile(nxDepsPath, cache);
}
function maxMTime(files) {
    return Math.max(...files.map((f) => f.mtime));
}
function rootWorkspaceFileData(workspaceFiles) {
    return [
        `package.json`,
        'workspace.json',
        'angular.json',
        `nx.json`,
        `tsconfig.json`,
    ].reduce((acc, curr) => {
        const fileData = workspaceFiles.find((x) => x.file === curr);
        if (fileData) {
            acc.push(fileData);
        }
        return acc;
    }, []);
}
function modifiedSinceCache(fileMap, c) {
    // No cache -> compute entire graph
    if (!c) {
        return { fileMap };
    }
    const cachedFileMap = c.data.fileMap;
    const currentProjects = Object.keys(fileMap).sort();
    const previousProjects = Object.keys(cachedFileMap).sort();
    // Projects changed -> compute entire graph
    if (currentProjects.length !== previousProjects.length ||
        currentProjects.some((val, idx) => val !== previousProjects[idx])) {
        return { fileMap };
    }
    // Projects are same -> compute projects with file changes
    const modifiedSince = {};
    currentProjects.forEach((p) => {
        let projectFilesChanged = false;
        for (const f of fileMap[p]) {
            const fromCache = cachedFileMap[p].find((x) => x.file === f.file);
            if (!fromCache || f.mtime > fromCache.mtime) {
                projectFilesChanged = true;
                break;
            }
        }
        if (projectFilesChanged) {
            modifiedSince[p] = fileMap[p];
        }
    });
    // Re-compute nodes and dependencies for each project in file map.
    Object.keys(modifiedSince).forEach((key) => {
        delete c.data.projectGraph.dependencies[key];
    });
    return { fileMap: modifiedSince, projectGraph: c.data.projectGraph };
}
//# sourceMappingURL=project-graph.js.map